{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe368bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "sys.path.append(os.path.abspath('C:/Users/vpming/tuni_ml/src'))\n",
    "from extract_data import build_cellwise_df\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd52410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/vpming/tuni_ml/data'\n",
    "df = build_cellwise_df(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e26d585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1750, 1001)\n",
      "[[3]\n",
      " [3]\n",
      " [2]\n",
      " ...\n",
      " [2]\n",
      " [2]\n",
      " [3]]\n"
     ]
    }
   ],
   "source": [
    "x = np.stack(df['time_trace'])\n",
    "print(x.shape)\n",
    "y = df['dis_to_target'].values\n",
    "print(y.reshape(-1,1))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "x_scaler = StandardScaler()\n",
    "x_train_s = x_scaler.fit_transform(x_train)\n",
    "x_test_s = x_scaler.transform(x_test)\n",
    "\n",
    "y_scaler = StandardScaler()\n",
    "y_train_s = y_scaler.fit_transform(y_train.reshape(-1,1)).ravel()\n",
    "y_test_s = y_scaler.transform(y_test.reshape(-1,1)).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0bfac851",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.tensor(x_train_s, dtype=torch.float32),\n",
    "                         torch.tensor(y_train_s, dtype=torch.float32))\n",
    "\n",
    "test_ds = TensorDataset(torch.tensor(x_test_s, dtype=torch.float32),\n",
    "                        torch.tensor(y_test_s, dtype=torch.float32))\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71f4ad30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,1)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39961c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1: Train loss 0.7237\n",
      "Epoch  2: Train loss 0.4744\n",
      "Epoch  3: Train loss 0.3796\n",
      "Epoch  4: Train loss 0.2983\n",
      "Epoch  5: Train loss 0.2539\n",
      "Epoch  6: Train loss 0.2150\n",
      "Epoch  7: Train loss 0.1799\n",
      "Epoch  8: Train loss 0.1564\n",
      "Epoch  9: Train loss 0.1375\n",
      "Epoch 10: Train loss 0.1263\n",
      "Epoch 11: Train loss 0.1040\n",
      "Epoch 12: Train loss 0.1001\n",
      "Epoch 13: Train loss 0.0969\n",
      "Epoch 14: Train loss 0.0812\n",
      "Epoch 15: Train loss 0.0782\n",
      "Epoch 16: Train loss 0.0645\n",
      "Epoch 17: Train loss 0.0587\n",
      "Epoch 18: Train loss 0.0638\n",
      "Epoch 19: Train loss 0.0550\n",
      "Epoch 20: Train loss 0.0473\n"
     ]
    }
   ],
   "source": [
    "model = MLP(x_train.shape[1])\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1:2d}: Train loss {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "torch.save({\n",
    "    'model_state': model.state_dict(),\n",
    "    'scaler_x': x_scaler,\n",
    "    'scaler_y': y_scaler\n",
    "}, 'C:/Users/vpming/tuni_ml/src/model/mlp_dtt.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93843369",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('C:/Users/vpming/tuni_ml/src/model/mlp_dtt.pt', weights_only=False)\n",
    "model = MLP(x_train.shape[1])\n",
    "model.load_state_dict(checkpoint['model_state'])\n",
    "model.eval()\n",
    "\n",
    "scaler_x = checkpoint['scaler_x']\n",
    "scaler_y = checkpoint['scaler_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4e701257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.2558973 2.1968734 2.3069746 1.7485405 1.9559821 3.1011918 1.9392272\n",
      " 1.5799947 2.6926613 2.287417  2.5216088 1.5297105 0.9830334 1.3135597\n",
      " 1.35044   2.6895366 2.0199523 1.4634914 1.5492975 1.6825321 2.0958734\n",
      " 1.6111461 1.3420255 2.3264484 2.3807058]\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "file_path = 'C:/Users/vpming/tuni_ml\\data\\stim_0.5_beta_0.04_noise_0.04_kcross_0.0050\\sim_data__stimMag_0.50_beta_0.40_noise_0.040_kcross_0.0050_nSamples_1000_5.h5'\n",
    "\n",
    "with h5py.File(file_path,'r') as f:\n",
    "    x_new = np.array(f['timeTraces']['2']).T\n",
    "\n",
    "x_new_scale = scaler_x.transform(x_new)\n",
    "with torch.no_grad():\n",
    "    pred_scaled = model(torch.tensor(x_new_scale, dtype=torch.float32)).numpy()\n",
    "pred = scaler_y.inverse_transform(pred_scaled.reshape(-1,1)).ravel()\n",
    "print(pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
